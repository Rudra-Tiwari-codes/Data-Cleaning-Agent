{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Powered Data Cleaning Agent - Main Demo\n",
        "\n",
        "**GenAI Competition - UoM DSCubed x UWA DSC**  \n",
        "**Author:** Rudra Tiwari  \n",
        "**Complete Data Cleaning Agent with WHO Health Data Support**\n",
        "\n",
        "---\n",
        "\n",
        "## What This Notebook Demonstrates:\n",
        "1. **Core Data Cleaning Engine** - Comprehensive data quality analysis and cleaning\n",
        "2. **AI-Powered Intelligence** - OpenAI integration for smart cleaning suggestions\n",
        "3. **WHO Health Data Processing** - Real-world health dataset cleaning\n",
        "4. **Multi-Sheet Excel Support** - Advanced Excel file handling\n",
        "5. **Interactive Visualizations** - Beautiful before/after comparisons\n",
        "6. **Professional Reporting** - Detailed cleaning reports and insights\n",
        "\n",
        "**This is the main demonstration notebook for the competition!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Required Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Data cleaning agent\n",
        "from data_cleaning_agent import DataCleaningAgent\n",
        "from ai_data_cleaning import AIDataCleaningAgent\n",
        "from config import OPENAI_API_KEY\n",
        "\n",
        "# Suppress warnings for clean output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(\"AI-Powered Data Cleaning Agent ready!\")\n",
        "print(f\"OpenAI API Key configured: {'Yes' if OPENAI_API_KEY != 'your-openai-api-key-here' else 'Please set in config.py'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialize AI-Powered Data Cleaning Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the AI-powered data cleaning agent\n",
        "agent = AIDataCleaningAgent()\n",
        "\n",
        "print(\"AI-Powered Data Cleaning Agent initialized!\")\n",
        "print(\"Features available:\")\n",
        "print(\"- Missing value detection and handling\")\n",
        "print(\"- Duplicate identification and removal\")\n",
        "print(\"- Data type optimization\")\n",
        "print(\"- Outlier detection and treatment\")\n",
        "print(\"- Text standardization\")\n",
        "print(\"- Memory optimization\")\n",
        "print(\"- AI-powered cleaning suggestions\")\n",
        "print(\"- Multi-sheet Excel support\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load and Clean WHO Health Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load WHO health data\n",
        "df = pd.read_csv('datasets/Life Expectancy Data.csv')\n",
        "\n",
        "print(\"WHO Health Data loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
        "\n",
        "# Show basic information\n",
        "print(\"\\nDataset Overview:\")\n",
        "print(df.info())\n",
        "\n",
        "# Show first few rows\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# Perform data quality analysis\n",
        "print(\"\\nData Quality Analysis:\")\n",
        "quality_report = agent.analyze_data_quality(df)\n",
        "print(f\"Overall Quality Score: {quality_report['overall_score']:.1f}%\")\n",
        "print(f\"Missing Values: {quality_report['missing_values']}\")\n",
        "print(f\"Duplicate Rows: {quality_report['duplicates']}\")\n",
        "print(f\"Outliers Detected: {quality_report['outliers']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Apply AI-Powered Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store original data for comparison\n",
        "original_df = df.copy()\n",
        "original_shape = df.shape\n",
        "original_memory = df.memory_usage(deep=True).sum() / 1024\n",
        "\n",
        "print(\"APPLYING AI-POWERED DATA CLEANING\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Original dataset: {original_shape[0]} rows × {original_shape[1]} columns\")\n",
        "print(f\"Original memory usage: {original_memory:.1f} KB\")\n",
        "\n",
        "# Apply comprehensive cleaning\n",
        "cleaned_df = agent.intelligent_clean(df)\n",
        "\n",
        "cleaned_shape = cleaned_df.shape\n",
        "cleaned_memory = cleaned_df.memory_usage(deep=True).sum() / 1024\n",
        "\n",
        "print(f\"\\nCleaned dataset: {cleaned_shape[0]} rows × {cleaned_shape[1]} columns\")\n",
        "print(f\"Cleaned memory usage: {cleaned_memory:.1f} KB\")\n",
        "\n",
        "# Calculate improvements\n",
        "rows_removed = original_shape[0] - cleaned_shape[0]\n",
        "memory_saved = original_memory - cleaned_memory\n",
        "memory_improvement = (memory_saved / original_memory) * 100\n",
        "\n",
        "print(f\"\\nCleaning Results:\")\n",
        "print(f\"- Rows removed: {rows_removed}\")\n",
        "print(f\"- Memory saved: {memory_saved:.1f} KB ({memory_improvement:.1f}% improvement)\")\n",
        "\n",
        "# Show cleaned data\n",
        "print(\"\\nCleaned Data Sample:\")\n",
        "display(cleaned_df.head())\n",
        "\n",
        "print(\"\\nAI-powered cleaning complete!\")\n",
        "print(\"Data is now ready for analysis and modeling.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Health Crisis Analysis with WHO Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import health crisis analyzer\n",
        "from features.health_crisis_analysis import analyze_health_data\n",
        "\n",
        "print(\"HEALTH CRISIS ANALYSIS\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Perform health crisis analysis on cleaned data\n",
        "crisis_analysis = analyze_health_data(cleaned_df)\n",
        "\n",
        "print(\"\\nHealth crisis analysis complete!\")\n",
        "print(\"This demonstrates real-world health data processing capabilities.\")\n",
        "print(\"Perfect for showing practical application in the hackathon demo!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AW"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
