{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Powered Data Cleaning Agent - Interactive Demo\n",
        "\n",
        "**GenAI Competition - UoM DSCubed x UWA DSC**  \n",
        "**Author:** Rudra Tiwari  \n",
        "**Perfect for Google Colab Demo!**\n",
        "\n",
        "---\n",
        "\n",
        "## What This Demo Does:\n",
        "1. **Step 1:** Load and examine your dataset\n",
        "2. **Step 2:** Show data quality issues\n",
        "3. **Step 3:** Get AI-powered cleaning suggestions\n",
        "4. **Step 4:** Apply intelligent cleaning\n",
        "5. **Step 5:** Show before/after comparison\n",
        "6. **Step 6:** Generate final report\n",
        "\n",
        "**Just upload your dataset and run each cell!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Install Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "%pip install pandas numpy matplotlib seaborn openpyxl langchain langchain-openai python-dotenv\n",
        "\n",
        "print(\"All libraries installed successfully!\")\n",
        "print(\"Ready to start the demo!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Upload Your Dataset\n",
        "\n",
        "**Upload your dataset file (CSV, Excel, or JSON) in the file uploader below:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import json\n",
        "import io\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Please upload your dataset file...\")\n",
        "print(\"Supported formats: CSV, Excel (.xlsx), JSON\")\n",
        "\n",
        "# File upload\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file\n",
        "if uploaded:\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    print(f\"File uploaded: {file_name}\")\n",
        "    \n",
        "    # Load the dataset based on file type\n",
        "    if file_name.endswith('.csv'):\n",
        "        df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "    elif file_name.endswith(('.xlsx', '.xls')):\n",
        "        df = pd.read_excel(io.BytesIO(uploaded[file_name]))\n",
        "    elif file_name.endswith('.json'):\n",
        "        df = pd.read_json(io.BytesIO(uploaded[file_name]))\n",
        "    else:\n",
        "        print(\"Unsupported file format\")\n",
        "        df = None\n",
        "    \n",
        "    if df is not None:\n",
        "        print(f\"Dataset loaded successfully!\")\n",
        "        print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
        "        print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
        "else:\n",
        "    print(\"No file uploaded\")\n",
        "    df = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 2: Examine Your Dataset\n",
        "\n",
        "**Let's take a detailed look at your data:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print(\"üîç DATASET EXAMINATION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Basic information\n",
        "    print(f\"üìä Dataset Overview:\")\n",
        "    print(f\"   - Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
        "    print(f\"   - Total cells: {df.shape[0] * df.shape[1]:,}\")\n",
        "    print(f\"   - Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
        "    \n",
        "    # Column information\n",
        "    print(f\"\\nüìù Column Information:\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"   {i:2d}. {col}\")\n",
        "    \n",
        "    # Data types\n",
        "    print(f\"\\nüîß Data Types:\")\n",
        "    dtype_counts = df.dtypes.value_counts()\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\"   - {dtype}: {count} columns\")\n",
        "    \n",
        "    # Show first few rows\n",
        "    print(f\"\\nüìä First 5 rows of your data:\")\n",
        "    display(df.head())\n",
        "    \n",
        "    print(f\"\\n‚úÖ Dataset examination complete!\")\n",
        "else:\n",
        "    print(\"‚ùå No dataset loaded. Please upload a file first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
